{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c1d4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kstest, norm, expon, gamma, lognorm, beta\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import scikit_posthocs as sp\n",
    "from scipy.stats import kruskal\n",
    "import statsmodels.stats.multicomp as mc\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import kstest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda9931",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "- The imported data is then processed Liar Dataset through the faKy library.\n",
    "- All the features, Readability, Information Complexity, Vader scores, NER, and POS tags are computed in a different notebook.\n",
    "- We have stored the data in a new data frame and now import this data frame for efficiency purposes.\n",
    "- We classify the qualative labels true(0), false(1) and in Between (2)\n",
    "- We also define in which columns the labels are stored in the data frame to compute the significance of the features \n",
    "- At last, we divide the data into three labels, True, False, and In between data corresponding with the qualitative labels 0,1,2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cea491ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Liar_computed = pd.read_csv('/Users/sandrobarreshamers/Thesis_IS_fake_news/ThesisData/Liar_computed_final_version.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "211ff4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>json_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>object</th>\n",
       "      <th>binary label</th>\n",
       "      <th>readability</th>\n",
       "      <th>compressed_size</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_NOUN</th>\n",
       "      <th>pos_NUM</th>\n",
       "      <th>pos_PART</th>\n",
       "      <th>pos_PRON</th>\n",
       "      <th>pos_PROPN</th>\n",
       "      <th>pos_PUNCT</th>\n",
       "      <th>pos_SCONJ</th>\n",
       "      <th>pos_SYM</th>\n",
       "      <th>pos_VERB</th>\n",
       "      <th>pos_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>2</td>\n",
       "      <td>71.815000</td>\n",
       "      <td>11444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>2</td>\n",
       "      <td>71.781579</td>\n",
       "      <td>9089</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.206</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     json_id        claim  \\\n",
       "0           0  10540.json    half-true   \n",
       "1           1    324.json  mostly-true   \n",
       "\n",
       "                                              object  binary label  \\\n",
       "0  When did the decline of coal start? It started...             2   \n",
       "1  Hillary Clinton agrees with John McCain \"by vo...             2   \n",
       "\n",
       "   readability  compressed_size  vader_neg  vader_neu  vader_pos  ...  \\\n",
       "0    71.815000            11444      0.000      0.902      0.098  ...   \n",
       "1    71.781579             9089      0.107      0.687      0.206  ...   \n",
       "\n",
       "   pos_NOUN  pos_NUM pos_PART pos_PRON  pos_PROPN  pos_PUNCT  pos_SCONJ  \\\n",
       "0       5.0      0.0      1.0      1.0        4.0        4.0        0.0   \n",
       "1       2.0      0.0      1.0      0.0        7.0        3.0        0.0   \n",
       "\n",
       "   pos_SYM  pos_VERB  pos_X  \n",
       "0      0.0       4.0    0.0  \n",
       "1      0.0       3.0    0.0  \n",
       "\n",
       "[2 rows x 51 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Liar_computed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a04c5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'json_id', 'claim', 'object', 'binary label',\n",
       "       'readability', 'compressed_size', 'vader_neg', 'vader_neu', 'vader_pos',\n",
       "       'vader_compound', 'tot_ner_count', 'ner_counts', 'input_vector_ner',\n",
       "       'NER_CARDINAL', 'NER_DATE', 'NER_EVENT', 'NER_FAC', 'NER_GPE',\n",
       "       'NER_LANGUAGE', 'NER_LAW', 'NER_LOC', 'NER_MONEY', 'NER_NORP',\n",
       "       'NER_ORDINAL', 'NER_ORG', 'NER_PERCENT', 'NER_PERSON', 'NER_PRODUCT',\n",
       "       'NER_QUANTITY', 'NER_TIME', 'NER_WORK_OF_ART', 'pos counts',\n",
       "       'input_vector_pos', 'pos_ADJ', 'pos_ADP', 'pos_ADV', 'pos_AUX',\n",
       "       'pos_CCONJ', 'pos_DET', 'pos_INTJ', 'pos_NOUN', 'pos_NUM', 'pos_PART',\n",
       "       'pos_PRON', 'pos_PROPN', 'pos_PUNCT', 'pos_SCONJ', 'pos_SYM',\n",
       "       'pos_VERB', 'pos_X'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Liar_computed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a4ef2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n",
      "2833\n",
      "5730\n"
     ]
    }
   ],
   "source": [
    "from faKy import values_by_label, dunn_table\n",
    "labels = [0, 1, 2]\n",
    "df_label = 'binary label'\n",
    "\n",
    "df_Liar_true = Liar_computed[(Liar_computed['binary label'] == 0)]\n",
    "df_Liar_false = Liar_computed[(Liar_computed['binary label'] == 1)]\n",
    "df_Liar_between = Liar_computed[(Liar_computed['binary label'] == 2)]\n",
    "\n",
    "print(len(df_Liar_true))\n",
    "print(len(df_Liar_false))\n",
    "print(len(df_Liar_between))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a725aa",
   "metadata": {},
   "source": [
    "# Kruskal Dunn tests\n",
    "- In this code block, we compute the Dunn tests for the different features; we first perform the Kruskal Wallis test (KST) to test the significance\n",
    "- Subsequently, we perform the ad-hoc Dunn test and test the significance of the features between the different qualitative labels\n",
    "- The KST is translated to a Dunn table through the faKy function dunn_table\n",
    "- All the Dunn tables are printed into latex format through the to_latex function and used in the research paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f988723",
   "metadata": {},
   "source": [
    "### Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b25d45c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal results:\n",
      "F-statistic: 49.863\n",
      "p-value: 1.487e-11\n"
     ]
    }
   ],
   "source": [
    "label_fke = values_by_label(Liar_computed, 'readability',labels,df_label)\n",
    "stat, p = kruskal(*label_fke) # unpack the elements \n",
    "\n",
    "print('Kruskal results:')\n",
    "print(f'F-statistic: {stat:.3f}')\n",
    "print(f'p-value: {p:.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf83af39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results for the FKE-readability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012227</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group          1            2                3       \n",
       "metric     value reject value reject     value reject\n",
       "1            1.0  False   0.0   True  0.012227   True\n",
       "2            0.0   True   1.0  False       0.0   True\n",
       "3       0.012227   True   0.0   True       1.0  False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunn_results = sp.posthoc_dunn(label_fke, p_adjust='bonferroni')\n",
    "df_dunn_R = dunn_table(dunn_results)\n",
    "\n",
    "print('Dunn results for the FKE-readability')\n",
    "dunn_table(dunn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02065f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex_table = df_dunn_R.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3d674",
   "metadata": {},
   "source": [
    "### Information Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3ed3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal results:\n",
      "F-statistic: 79.409\n",
      "p-value: 5.710e-18\n"
     ]
    }
   ],
   "source": [
    "label_com = values_by_label(Liar_computed, 'compressed_size',labels, df_label)\n",
    "stat, p = kruskal(*label_com) # unpack the elements \n",
    "\n",
    "print('Kruskal results:')\n",
    "print(f'F-statistic: {stat:.3f}')\n",
    "print(f'p-value: {p:.3e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55e15ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results for the Information Complexity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028695</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028695</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group          1               2                3       \n",
       "metric     value reject    value reject     value reject\n",
       "1            1.0  False  0.00005   True  0.028695   True\n",
       "2        0.00005   True      1.0  False       0.0   True\n",
       "3       0.028695   True      0.0   True       1.0  False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunn_results = sp.posthoc_dunn(label_com, p_adjust='bonferroni')\n",
    "print('Dunn results for the Information Complexity')\n",
    "df_dunn_IC = dunn_table(dunn_results)\n",
    "df_dunn_IC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9451f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex_table_DIC = df_dunn_IC.to_latex(index=False, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891b7e8",
   "metadata": {},
   "source": [
    "### VADER labels\n",
    "- Since we have multiple Vader scores we need to compute the Dunn KST over the different labels\n",
    "- this code snippet iterates over three tables simultaneously and prints the formatted values of Vader, stat, and p in each iteration. \n",
    "- Also, for the Dunn table, we need to compute extra steps.\n",
    "- The code performs the Dunn table method, stores the results in DataFrames, and assigns those DataFrames to specific keys in the df_dict dictionary. It then prints the results for each iteration of the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f46e8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader_neg : fstat 10.409693080422452; p 0.005489892854085175\n",
      "vader_neu : fstat 10.17546297354846; p 0.00617200529376983\n",
      "vader_pos : fstat 4.323321766239063; p 0.11513373846730762\n",
      "vader_compound : fstat 1.999867736891534; p 0.36790377041511385\n"
     ]
    }
   ],
   "source": [
    "vader_labels = ['vader_neg', 'vader_neu', 'vader_pos', 'vader_compound']\n",
    "\n",
    "computed_labels = []\n",
    "for vader in vader_labels:\n",
    "    label_vader = values_by_label(Liar_computed, vader,labels,df_label)\n",
    "    stat, p = kruskal(*label_vader) # unpack the elements\n",
    "    computed_labels.append([stat, p])\n",
    "\n",
    "for i, (stat, p), vader in zip(range(len(computed_labels)), computed_labels, vader_labels):\n",
    "    print(f'{vader} : fstat {stat}; p {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18d974b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results: vader_neg\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False       1.0  False  0.022119   True\n",
      "2            1.0  False       1.0  False  0.041474   True\n",
      "3       0.022119   True  0.041474   True       1.0  False\n",
      "Dunn results: vader_neu\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.060342  False  0.004317   True\n",
      "2       0.060342  False       1.0  False       1.0  False\n",
      "3       0.004317   True       1.0  False       1.0  False\n",
      "Dunn results: vader_pos\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.144254  False  0.197013  False\n",
      "2       0.144254  False       1.0  False       1.0  False\n",
      "3       0.197013  False       1.0  False       1.0  False\n",
      "Dunn results: vader_compound\n",
      "group      1                2                3       \n",
      "metric value reject     value reject     value reject\n",
      "1        1.0  False       1.0  False       1.0  False\n",
      "2        1.0  False       1.0  False  0.516025  False\n",
      "3        1.0  False  0.516025  False       1.0  False\n"
     ]
    }
   ],
   "source": [
    "df_dict = {\n",
    "    \"vader_neg\": pd.DataFrame(),\n",
    "    \"vader_neu\": pd.DataFrame(),\n",
    "    \"vader_pos\": pd.DataFrame(),\n",
    "    \"vader_compound\": pd.DataFrame()\n",
    "}\n",
    "\n",
    "for vader in vader_labels:\n",
    "    label_vader = values_by_label(Liar_computed, vader, labels, df_label)\n",
    "    dunn_results = sp.posthoc_dunn(label_vader, p_adjust='bonferroni')\n",
    "    result_dunn_test = dunn_table(dunn_results)\n",
    "    \n",
    "    df_dict[vader] = result_dunn_test\n",
    "        \n",
    "    print(f'Dunn results: {vader}')\n",
    "    print(result_dunn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5ae5435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vader_results = pd.concat([df_dict[\"vader_neg\"], df_dict[\"vader_neu\"], df_dict[\"vader_pos\"], df_dict[\"vader_compound\"]], axis=1)\n",
    "#vader_results.columns = vader_results.columns.set_names(['Dunn results', 'metric'])\n",
    "#vader_results = vader_results.reset_index()\n",
    "#print(vader_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84db760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex_table_vader = vader_results.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fa5f7",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08bc2383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER count results:\n",
      "F-statistic: 42.182\n",
      "p-value: 6.924e-10\n"
     ]
    }
   ],
   "source": [
    "label_ner_sum = values_by_label(Liar_computed, 'tot_ner_count',labels,df_label)\n",
    "stat, p = kruskal(*label_ner_sum) \n",
    "\n",
    "print('NER count results:')\n",
    "print(f'F-statistic: {stat:.3f}')\n",
    "print(f'p-value: {p:.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41885d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results for the total NER count\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.001408   True  0.413233  False\n",
      "2       0.001408   True       1.0  False       0.0   True\n",
      "3       0.413233  False       0.0   True       1.0  False\n"
     ]
    }
   ],
   "source": [
    "dunn_results = sp.posthoc_dunn(label_ner_sum, p_adjust='bonferroni')\n",
    "\n",
    "print('Dunn results for the total NER count')\n",
    "df_dunn_NER = dunn_table(dunn_results)\n",
    "print(df_dunn_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b1eea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex_table = df_dunn_NER.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d07872",
   "metadata": {},
   "source": [
    "### NER counts tag\n",
    "- Similar to the VSS we need to compute the scores over the different NER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75dac54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_CARDINAL : fstat 49.83110092286668; p 1.5111720797740373e-11\n",
      "NER_DATE : fstat 51.61532051517984; p 6.192636087610597e-12\n",
      "NER_EVENT : fstat 0.17192881583577338; p 0.9176268908905847\n",
      "NER_FAC : fstat 1.62191142550578; p 0.44443311279487685\n",
      "NER_GPE : fstat 4.891785484232781; p 0.08664874537809603\n",
      "NER_LANGUAGE : fstat 0.2765099377408568; p 0.8708766170086077\n",
      "NER_LAW : fstat 5.044810889786552; p 0.08026629818911608\n",
      "NER_LOC : fstat 0.4509002696889834; p 0.7981568596715132\n",
      "NER_MONEY : fstat 35.30762339462919; p 2.1530147012843794e-08\n",
      "NER_NORP : fstat 0.7534040417699982; p 0.6861204930154862\n",
      "NER_ORDINAL : fstat 13.269417872165102; p 0.0013139611361827818\n",
      "NER_ORG : fstat 15.497830751288278; p 0.00043120998788284286\n",
      "NER_PERCENT : fstat 51.19931270863278; p 7.624484865681605e-12\n",
      "NER_PERSON : fstat 82.52962410037611; p 1.1992778976434277e-18\n",
      "NER_PRODUCT : fstat 1.096845519071406; p 0.5778605169801413\n",
      "NER_QUANTITY : fstat 3.320164395658514; p 0.19012335173241685\n",
      "NER_TIME : fstat 3.710352636538486; p 0.15642535959465625\n",
      "NER_WORK_OF_ART : fstat 9.313248559339161; p 0.00949847252951896\n"
     ]
    }
   ],
   "source": [
    "ner_labels = [ 'NER_CARDINAL',\n",
    "       'NER_DATE', 'NER_EVENT', 'NER_FAC', 'NER_GPE', 'NER_LANGUAGE',\n",
    "       'NER_LAW', 'NER_LOC', 'NER_MONEY', 'NER_NORP', 'NER_ORDINAL', 'NER_ORG',\n",
    "       'NER_PERCENT', 'NER_PERSON', 'NER_PRODUCT', 'NER_QUANTITY', 'NER_TIME',\n",
    "       'NER_WORK_OF_ART']\n",
    "computed_ner_labels = []\n",
    "for ner in ner_labels:\n",
    "    label_ner = values_by_label(Liar_computed, ner, labels, df_label)\n",
    "    stat, p = kruskal(*label_ner) # unpack the elements \n",
    "    computed_ner_labels.append([stat, p])\n",
    "\n",
    "for i, (stat, p), pos in zip(range(len(computed_ner_labels)), computed_ner_labels, ner_labels):\n",
    "       print(f'{pos} : fstat {stat}; p {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1dfe189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results: NER_CARDINAL\n",
      "group      1            2            3       \n",
      "metric value reject value reject value reject\n",
      "1        1.0  False   0.0   True   1.0  False\n",
      "2        0.0   True   1.0  False   0.0   True\n",
      "3        1.0  False   0.0   True   1.0  False\n",
      "Dunn results: NER_DATE\n",
      "group          1            2                3       \n",
      "metric     value reject value reject     value reject\n",
      "1            1.0  False   0.0   True  0.020809   True\n",
      "2            0.0   True   1.0  False       0.0   True\n",
      "3       0.020809   True   0.0   True       1.0  False\n",
      "Dunn results: NER_EVENT\n",
      "group      1            2            3       \n",
      "metric value reject value reject value reject\n",
      "1        1.0  False   1.0  False   1.0  False\n",
      "2        1.0  False   1.0  False   1.0  False\n",
      "3        1.0  False   1.0  False   1.0  False\n",
      "Dunn results: NER_FAC\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.644083  False  0.852657  False\n",
      "2       0.644083  False       1.0  False       1.0  False\n",
      "3       0.852657  False       1.0  False       1.0  False\n",
      "Dunn results: NER_GPE\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.088336  False  0.644748  False\n",
      "2       0.088336  False       1.0  False  0.464986  False\n",
      "3       0.644748  False  0.464986  False       1.0  False\n",
      "Dunn results: NER_LANGUAGE\n",
      "group      1            2            3       \n",
      "metric value reject value reject value reject\n",
      "1        1.0  False   1.0  False   1.0  False\n",
      "2        1.0  False   1.0  False   1.0  False\n",
      "3        1.0  False   1.0  False   1.0  False\n",
      "Dunn results: NER_LAW\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.253646  False  0.076469  False\n",
      "2       0.253646  False       1.0  False       1.0  False\n",
      "3       0.076469  False       1.0  False       1.0  False\n",
      "Dunn results: NER_LOC\n",
      "group      1            2            3       \n",
      "metric value reject value reject value reject\n",
      "1        1.0  False   1.0  False   1.0  False\n",
      "2        1.0  False   1.0  False   1.0  False\n",
      "3        1.0  False   1.0  False   1.0  False\n",
      "Dunn results: NER_MONEY\n",
      "group          1            2                3       \n",
      "metric     value reject value reject     value reject\n",
      "1            1.0  False   1.0  False  0.000786   True\n",
      "2            1.0  False   1.0  False       0.0   True\n",
      "3       0.000786   True   0.0   True       1.0  False\n",
      "Dunn results: NER_NORP\n",
      "group      1            2            3       \n",
      "metric value reject value reject value reject\n",
      "1        1.0  False   1.0  False   1.0  False\n",
      "2        1.0  False   1.0  False   1.0  False\n",
      "3        1.0  False   1.0  False   1.0  False\n",
      "Dunn results: NER_ORDINAL\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.000855   True  0.064517  False\n",
      "2       0.000855   True       1.0  False    0.1102  False\n",
      "3       0.064517  False    0.1102  False       1.0  False\n",
      "Dunn results: NER_ORG\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.003574   True       1.0  False\n",
      "2       0.003574   True       1.0  False  0.001141   True\n",
      "3            1.0  False  0.001141   True       1.0  False\n",
      "Dunn results: NER_PERCENT\n",
      "group          1            2                3       \n",
      "metric     value reject value reject     value reject\n",
      "1            1.0  False   0.0   True  0.674264  False\n",
      "2            0.0   True   1.0  False       0.0   True\n",
      "3       0.674264  False   0.0   True       1.0  False\n",
      "Dunn results: NER_PERSON\n",
      "group      1                2                3       \n",
      "metric value reject     value reject     value reject\n",
      "1        1.0  False       0.0   True       0.0   True\n",
      "2        0.0   True       1.0  False  0.000813   True\n",
      "3        0.0   True  0.000813   True       1.0  False\n",
      "Dunn results: NER_PRODUCT\n",
      "group          1            2                3       \n",
      "metric     value reject value reject     value reject\n",
      "1            1.0  False   1.0  False  0.900096  False\n",
      "2            1.0  False   1.0  False       1.0  False\n",
      "3       0.900096  False   1.0  False       1.0  False\n",
      "Dunn results: NER_QUANTITY\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.218648  False  0.923014  False\n",
      "2       0.218648  False       1.0  False  0.722318  False\n",
      "3       0.923014  False  0.722318  False       1.0  False\n",
      "Dunn results: NER_TIME\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.457972  False       1.0  False\n",
      "2       0.457972  False       1.0  False  0.201008  False\n",
      "3            1.0  False  0.201008  False       1.0  False\n",
      "Dunn results: NER_WORK_OF_ART\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.586245  False  0.842654  False\n",
      "2       0.586245  False       1.0  False  0.007074   True\n",
      "3       0.842654  False  0.007074   True       1.0  False\n"
     ]
    }
   ],
   "source": [
    "for ner in ner_labels:\n",
    "    label_ner = values_by_label(Liar_computed, ner, labels, df_label)\n",
    "    dunn_results = sp.posthoc_dunn(label_ner, p_adjust='bonferroni')\n",
    "    result_dunn_test_ner = dunn_table(dunn_results)\n",
    "    \n",
    "    df_dict_ner[ner] = result_dunn_test_ner\n",
    "        \n",
    "    print(f'Dunn results: {ner}')\n",
    "    print(result_dunn_test_ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12ec3e56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_list_ner = []\n",
    "\n",
    "#for label in df_dict_ner.keys():\n",
    "#   df_list_ner.append(df_dict_ner[label])\n",
    "\n",
    "#result_ner_tag = pd.concat(df_list_ner, axis=0)\n",
    "\n",
    "#result_ner_tag.columns = result_ner_tag.columns.set_names(['Dunn results', 'metric'])\n",
    "#result_ner_tag = result_ner_tag.reset_index()\n",
    "\n",
    "#print(result_ner_tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f114025",
   "metadata": {},
   "source": [
    "### Significant features:\n",
    "- CARDINAL p 0.0\n",
    "- DATE  p 0.0\n",
    "- ORDINAL p 0.0\n",
    "- ORG p 0.0\n",
    "- PERCENT 0.0\n",
    "- PERSON 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a1f5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex_table_ner_tags = result_ner_tag.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table_ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e8858",
   "metadata": {},
   "source": [
    "### Pos labels\n",
    "- Similar to VSS and NER we compute the KST and Dunn test for all the POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b079fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_ADJ : fstat 75.63363133229193; p 3.7702107990073795e-17\n",
      "pos_ADP : fstat 52.88463642780589; p 3.2828203050086716e-12\n",
      "pos_ADV : fstat 15.343928130378757; p 0.000465702255291164\n",
      "pos_AUX : fstat 10.672755272313356; p 0.004813274601537372\n",
      "pos_CCONJ : fstat 30.78256967100686; p 2.0684733341776858e-07\n",
      "pos_DET : fstat 17.70000951293461; p 0.0001433810542873743\n",
      "pos_INTJ : fstat 1.6205299951697043; p 0.44474019552820465\n",
      "pos_NOUN : fstat 74.42562883952174; p 6.897314694451533e-17\n",
      "pos_NUM : fstat 157.83110536457033; p 5.33839781071815e-35\n",
      "pos_PART : fstat 15.798490526270482; p 0.0003710234598959158\n",
      "pos_PRON : fstat 6.770194727289172; p 0.03387434405551494\n",
      "pos_PROPN : fstat 49.15895156684152; p 2.1147999875958165e-11\n",
      "pos_PUNCT : fstat 39.48929409787203; p 2.6607786034061635e-09\n",
      "pos_SCONJ : fstat 50.565192976835576; p 1.0469064051354758e-11\n",
      "pos_SYM : fstat 27.912685893597782; p 8.686348924034588e-07\n",
      "pos_VERB : fstat 45.05819719363287; p 1.6433754586485928e-10\n",
      "pos_X : fstat 4.769992151936845; p 0.092089340940054\n"
     ]
    }
   ],
   "source": [
    "pos_labels = [ 'pos_ADJ',\n",
    "       'pos_ADP', 'pos_ADV', 'pos_AUX', 'pos_CCONJ', 'pos_DET', 'pos_INTJ',\n",
    "       'pos_NOUN', 'pos_NUM', 'pos_PART', 'pos_PRON', 'pos_PROPN', 'pos_PUNCT',\n",
    "       'pos_SCONJ', 'pos_SYM', 'pos_VERB', 'pos_X']\n",
    "\n",
    "computed_pos_labels = []\n",
    "for pos in pos_labels:\n",
    "    label_pos = values_by_label(Liar_computed, pos, labels, df_label)\n",
    "    stat, p = kruskal(*label_pos) # unpack the elements\n",
    "    computed_pos_labels.append([stat, p])\n",
    "\n",
    "for i, (stat, p), pos in zip(range(len(computed_pos_labels)), computed_pos_labels, pos_labels):\n",
    "       print(f'{pos} : fstat {stat}; p {p}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7bcddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results: pos_ADJ\n",
      "group          1            2                3       \n",
      "metric     value reject value reject     value reject\n",
      "1            1.0  False   0.0   True  0.895962  False\n",
      "2            0.0   True   1.0  False       0.0   True\n",
      "3       0.895962  False   0.0   True       1.0  False\n",
      "Dunn results: pos_ADP\n",
      "group      1            2            3       \n",
      "metric value reject value reject value reject\n",
      "1        1.0  False   0.0   True   1.0  False\n",
      "2        0.0   True   1.0  False   0.0   True\n",
      "3        1.0  False   0.0   True   1.0  False\n",
      "Dunn results: pos_ADV\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.003806   True       1.0  False\n",
      "2       0.003806   True       1.0  False  0.001214   True\n",
      "3            1.0  False  0.001214   True       1.0  False\n",
      "Dunn results: pos_AUX\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.007976   True  0.007729   True\n",
      "2       0.007976   True       1.0  False       1.0  False\n",
      "3       0.007729   True       1.0  False       1.0  False\n",
      "Dunn results: pos_CCONJ\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.049258   True  0.167184  False\n",
      "2       0.049258   True       1.0  False       0.0   True\n",
      "3       0.167184  False       0.0   True       1.0  False\n",
      "Dunn results: pos_DET\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.001194   True       1.0  False\n",
      "2       0.001194   True       1.0  False  0.000563   True\n",
      "3            1.0  False  0.000563   True       1.0  False\n",
      "Dunn results: pos_INTJ\n",
      "group      1                2                3       \n",
      "metric value reject     value reject     value reject\n",
      "1        1.0  False       1.0  False       1.0  False\n",
      "2        1.0  False       1.0  False  0.609091  False\n",
      "3        1.0  False  0.609091  False       1.0  False\n",
      "Dunn results: pos_NOUN\n",
      "group          1            2                3       \n",
      "metric     value reject value reject     value reject\n",
      "1            1.0  False   0.0   True  0.677504  False\n",
      "2            0.0   True   1.0  False       0.0   True\n",
      "3       0.677504  False   0.0   True       1.0  False\n",
      "Dunn results: pos_NUM\n",
      "group      1            2            3       \n",
      "metric value reject value reject value reject\n",
      "1        1.0  False   0.0   True   1.0  False\n",
      "2        0.0   True   1.0  False   0.0   True\n",
      "3        1.0  False   0.0   True   1.0  False\n",
      "Dunn results: pos_PART\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.000212   True  0.019654   True\n",
      "2       0.000212   True       1.0  False  0.122624  False\n",
      "3       0.019654   True  0.122624  False       1.0  False\n",
      "Dunn results: pos_PRON\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.087848  False       1.0  False\n",
      "2       0.087848  False       1.0  False  0.061229  False\n",
      "3            1.0  False  0.061229  False       1.0  False\n",
      "Dunn results: pos_PROPN\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False       0.0   True  0.000013   True\n",
      "2            0.0   True       1.0  False  0.000368   True\n",
      "3       0.000013   True  0.000368   True       1.0  False\n",
      "Dunn results: pos_PUNCT\n",
      "group          1               2                3       \n",
      "metric     value reject    value reject     value reject\n",
      "1            1.0  False  0.00103   True  0.683359  False\n",
      "2        0.00103   True      1.0  False       0.0   True\n",
      "3       0.683359  False      0.0   True       1.0  False\n",
      "Dunn results: pos_SCONJ\n",
      "group          1            2                3       \n",
      "metric     value reject value reject     value reject\n",
      "1            1.0  False   0.0   True  0.180944  False\n",
      "2            0.0   True   1.0  False       0.0   True\n",
      "3       0.180944  False   0.0   True       1.0  False\n",
      "Dunn results: pos_SYM\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False       1.0  False  0.000556   True\n",
      "2            1.0  False       1.0  False  0.000012   True\n",
      "3       0.000556   True  0.000012   True       1.0  False\n",
      "Dunn results: pos_VERB\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.000021   True       0.0   True\n",
      "2       0.000021   True       1.0  False  0.114084  False\n",
      "3            0.0   True  0.114084  False       1.0  False\n",
      "Dunn results: pos_X\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.091236  False  0.257834  False\n",
      "2       0.091236  False       1.0  False       1.0  False\n",
      "3       0.257834  False       1.0  False       1.0  False\n"
     ]
    }
   ],
   "source": [
    "for pos in pos_labels:\n",
    "    label_pos = values_by_label(Liar_computed, pos,labels,df_label)\n",
    "    dunn_results = sp.posthoc_dunn(label_pos, p_adjust='bonferroni')\n",
    "    result_dunn_test_pos = dunn_table(dunn_results)\n",
    "    df_dict_pos[pos] = result_dunn_test_pos\n",
    "        \n",
    "    print(f'Dunn results: {pos}')\n",
    "    print(result_dunn_test_pos)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adfada9",
   "metadata": {},
   "source": [
    "### Significant POS features\n",
    "- ADJ p: 0.00\n",
    "- ADP p: 0.00\n",
    "- AUX p: 0.01\n",
    "- CCONJ p: 0.05\n",
    "- DET p: 0.00\n",
    "- NOUN p: 0.00\n",
    "- NUM p:0.00\n",
    "- PART p:0.00\n",
    "- PUNCT p:0.00\n",
    "- SCONJ p: 0.00\n",
    "- VERB p:0 .00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af59d7f",
   "metadata": {},
   "source": [
    "## aggregate results\n",
    "- This section computes the aggregate results for the Continous and Discrete values\n",
    "- we define a function get_stats that computes the relevant statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cd92cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(df, column_name):\n",
    "    avg = df[column_name].mean()\n",
    "    max_val = df[column_name].max()\n",
    "    mode = df[column_name].mode()[0]\n",
    "    std = df[column_name].std()\n",
    "    return pd.DataFrame({'avg': [avg], 'max': [max_val], 'most common': [mode], 'std': [std]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab07a5e",
   "metadata": {},
   "source": [
    "### Continous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9412f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = ['compressed_size', 'readability']\n",
    "df_Liar_true_agg = df_Liar_true[stat_columns]\n",
    "df_Liar_false_agg = df_Liar_false[stat_columns]\n",
    "df_Liar_between_agg = df_Liar_between[stat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d55d8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = ['compressed_size', 'readability']\n",
    "labels = [0, 1, 2]\n",
    "\n",
    "rows = []\n",
    "for feature in stat_columns:\n",
    "    for label in labels:\n",
    "        df = Liar_computed[Liar_computed['binary label'] == label][[feature]]\n",
    "        stats = get_stats(df, feature)\n",
    "        rows.append({'feature': feature, 'label': label, 'avg': stats.iloc[0]['avg'], 'max': stats.iloc[0]['max'], \n",
    "                     'most common': stats.iloc[0]['most common'],'std': stats.iloc[0]['std']})\n",
    "        \n",
    "df_stats = pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b2c1178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "      <th>avg</th>\n",
       "      <th>max</th>\n",
       "      <th>most common</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compressed_size</td>\n",
       "      <td>0</td>\n",
       "      <td>8555.408711</td>\n",
       "      <td>149838.000000</td>\n",
       "      <td>5219.000</td>\n",
       "      <td>4779.221222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>compressed_size</td>\n",
       "      <td>1</td>\n",
       "      <td>8130.946347</td>\n",
       "      <td>197588.000000</td>\n",
       "      <td>5999.000</td>\n",
       "      <td>4929.493438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>compressed_size</td>\n",
       "      <td>2</td>\n",
       "      <td>8776.261955</td>\n",
       "      <td>294079.000000</td>\n",
       "      <td>6366.000</td>\n",
       "      <td>5112.226317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>readability</td>\n",
       "      <td>0</td>\n",
       "      <td>60.759599</td>\n",
       "      <td>127.215714</td>\n",
       "      <td>74.270</td>\n",
       "      <td>21.520138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>readability</td>\n",
       "      <td>1</td>\n",
       "      <td>56.334270</td>\n",
       "      <td>124.155000</td>\n",
       "      <td>60.705</td>\n",
       "      <td>22.948483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  label          avg            max  most common  \\\n",
       "0  compressed_size      0  8555.408711  149838.000000     5219.000   \n",
       "1  compressed_size      1  8130.946347  197588.000000     5999.000   \n",
       "2  compressed_size      2  8776.261955  294079.000000     6366.000   \n",
       "3      readability      0    60.759599     127.215714       74.270   \n",
       "4      readability      1    56.334270     124.155000       60.705   \n",
       "\n",
       "           std  \n",
       "0  4779.221222  \n",
       "1  4929.493438  \n",
       "2  5112.226317  \n",
       "3    21.520138  \n",
       "4    22.948483  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b4d40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex_table = df_stats.to_latex(index=False, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456787c3",
   "metadata": {},
   "source": [
    "### Discrete values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96eef43",
   "metadata": {},
   "source": [
    "- total sum of the counts\n",
    "- average sum of count /total\n",
    "- max number of count for a individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0314bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_features = ['tot_ner_count','NER_CARDINAL', 'NER_DATE','NER_ORDINAL', 'NER_ORG','NER_PERCENT', 'NER_PERSON', \n",
    "                  'pos_ADJ','pos_ADP','pos_AUX', 'pos_CCONJ', 'pos_DET', 'pos_NOUN','pos_NUM','pos_PART',\n",
    "                    'pos_PUNCT', 'pos_SCONJ','pos_VERB', ]\n",
    "df_Liar_true_count = df_Liar_true[count_features]\n",
    "df_Liar_false_count = df_Liar_false[count_features]\n",
    "df_Liar_between_count = df_Liar_between[count_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6b96ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_counts = pd.concat([df_Liar_true[count_features].max(axis=0), df_Liar_false[count_features].max(axis=0),\n",
    "                        df_Liar_between[count_features].max(axis=0)], axis=1)\n",
    "avg = pd.concat([df_Liar_true[count_features].mean(axis=0), df_Liar_false[count_features].mean(axis=0),\n",
    "                        df_Liar_between[count_features].mean(axis=0)], axis=1)\n",
    "\n",
    "std = pd.concat([df_Liar_true[count_features].std(axis=0), df_Liar_false[count_features].std(axis=0),\n",
    "                 df_Liar_between[count_features].std(axis=0)], axis=1)\n",
    "feature_count_stats = pd.DataFrame(index=count_features, columns=['Max Counts','avg','std'])\n",
    "\n",
    "\n",
    "feature_count_stats['std'] = list(zip(std[0].round(2), std[1].round(2), std[2].round(2)))\n",
    "\n",
    "\n",
    "feature_count_stats['Max Counts'] = list(zip(max_counts[0].astype(int), max_counts[1].astype(int), max_counts[2].astype(int)))\n",
    "feature_count_stats['avg'] = list(zip(avg[0].round(2), avg[1].round(2), avg[2].round(2)))\n",
    "\n",
    "\n",
    "feature_count_stats.index.name = 'Feature'\n",
    "\n",
    "#print(feature_count_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f72ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max Counts</th>\n",
       "      <th>avg</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tot_ner_count</th>\n",
       "      <td>(42, 59, 69)</td>\n",
       "      <td>(2.28, 2.12, 2.33)</td>\n",
       "      <td>(1.76, 1.78, 1.74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NER_CARDINAL</th>\n",
       "      <td>(5, 5, 6)</td>\n",
       "      <td>(0.29, 0.19, 0.28)</td>\n",
       "      <td>(0.6, 0.48, 0.58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NER_DATE</th>\n",
       "      <td>(5, 4, 4)</td>\n",
       "      <td>(0.32, 0.21, 0.28)</td>\n",
       "      <td>(0.62, 0.48, 0.57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NER_ORDINAL</th>\n",
       "      <td>(2, 2, 3)</td>\n",
       "      <td>(0.05, 0.03, 0.04)</td>\n",
       "      <td>(0.24, 0.18, 0.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NER_ORG</th>\n",
       "      <td>(7, 12, 16)</td>\n",
       "      <td>(0.32, 0.36, 0.32)</td>\n",
       "      <td>(0.63, 0.64, 0.63)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Max Counts                 avg                 std\n",
       "Feature                                                            \n",
       "tot_ner_count  (42, 59, 69)  (2.28, 2.12, 2.33)  (1.76, 1.78, 1.74)\n",
       "NER_CARDINAL      (5, 5, 6)  (0.29, 0.19, 0.28)   (0.6, 0.48, 0.58)\n",
       "NER_DATE          (5, 4, 4)  (0.32, 0.21, 0.28)  (0.62, 0.48, 0.57)\n",
       "NER_ORDINAL       (2, 2, 3)  (0.05, 0.03, 0.04)  (0.24, 0.18, 0.21)\n",
       "NER_ORG         (7, 12, 16)  (0.32, 0.36, 0.32)  (0.63, 0.64, 0.63)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_count_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98fb9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latex_table = feature_count_stats.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369db41",
   "metadata": {},
   "source": [
    "### End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
