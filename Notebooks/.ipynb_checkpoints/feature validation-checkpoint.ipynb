{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1d4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic libraries\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "#Visiualization and ML libraries\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import scikit_posthocs as sp\n",
    "from scipy.stats import kruskal\n",
    "import statsmodels.stats.multicomp as mc\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea491ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Liar_computed = pd.read_csv('/Users/sandrobarreshamers/Thesis_IS_fake_news/ThesisData/Liar_computed_v2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aca2780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'json_id', 'claim', 'object', 'binary label',\n",
       "       'compressed_size', 'readability', 'vader_neg', 'vader_neu', 'vader_pos',\n",
       "       'vader_compound', 'tot_ner_count', 'ner_counts', 'input_vector_ner',\n",
       "       'NER_CARDINAL', 'NER_DATE', 'NER_EVENT', 'NER_FAC', 'NER_GPE',\n",
       "       'NER_LANGUAGE', 'NER_LAW', 'NER_LOC', 'NER_MONEY', 'NER_NORP',\n",
       "       'NER_ORDINAL', 'NER_ORG', 'NER_PERCENT', 'NER_PERSON', 'NER_PRODUCT',\n",
       "       'NER_QUANTITY', 'NER_TIME', 'NER_WORK_OF_ART', 'pos counts',\n",
       "       'input_vector_pos', 'pos_ADJ', 'pos_ADP', 'pos_ADV', 'pos_AUX',\n",
       "       'pos_CCONJ', 'pos_DET', 'pos_INTJ', 'pos_NOUN', 'pos_NUM', 'pos_PART',\n",
       "       'pos_PRON', 'pos_PROPN', 'pos_PUNCT', 'pos_SCONJ', 'pos_SYM',\n",
       "       'pos_VERB', 'pos_X'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Liar_computed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4ef2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sandrobarreshamers/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n",
      "2833\n",
      "5730\n"
     ]
    }
   ],
   "source": [
    "from faKy import values_by_label, dunn_table\n",
    "labels = [0, 1, 2]\n",
    "df_label = 'binary label'\n",
    "\n",
    "df_Liar_true = Liar_computed[(Liar_computed['binary label'] == 0)]\n",
    "df_Liar_false = Liar_computed[(Liar_computed['binary label'] == 1)]\n",
    "df_Liar_between = Liar_computed[(Liar_computed['binary label'] == 2)]\n",
    "\n",
    "print(len(df_Liar_true))\n",
    "print(len(df_Liar_false))\n",
    "print(len(df_Liar_between))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b597d",
   "metadata": {},
   "source": [
    "### Test for parametic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532eb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_attributes = ['compressed_size', 'readability', 'vader_neg', 'vader_neu', 'vader_pos', \n",
    "                      'vader_compound']\n",
    "qa_dict = {}\n",
    "for qa in quality_attributes:\n",
    "    qa_dict[qa] = pd.to_numeric(Liar_computed[qa], errors='coerce').dropna().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a92471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                QA  non-parametric  p-value\n",
      "0  compressed_size            True      0.0\n",
      "1      readability            True      0.0\n",
      "2        vader_neg            True      0.0\n",
      "3        vader_neu            True      0.0\n",
      "4        vader_pos            True      0.0\n",
      "5   vader_compound            True      0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "test_result = []\n",
    "for qa in quality_attributes:\n",
    "    stat, p = kstest(qa_dict[qa], 'norm')\n",
    "    test_result.append({'QA': qa, 'non-parametric': p < 0.05, 'p-value': p})\n",
    "\n",
    "kolmogorov_smirnof_results = pd.DataFrame(test_result)\n",
    "\n",
    "print(kolmogorov_smirnof_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45db54db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llr}\n",
      "\\toprule\n",
      "             QA &  non-parametric &  p-value \\\\\n",
      "\\midrule\n",
      "compressed\\_size &            True &     0.00 \\\\\n",
      "    readability &            True &     0.00 \\\\\n",
      "      vader\\_neg &            True &     0.00 \\\\\n",
      "      vader\\_neu &            True &     0.00 \\\\\n",
      "      vader\\_pos &            True &     0.00 \\\\\n",
      " vader\\_compound &            True &     0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3665055642.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = kolmogorov_smirnof_results.to_latex(index=False, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "latex_table = kolmogorov_smirnof_results.to_latex(index=False, float_format=lambda x: \"%.2f\" % x)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a725aa",
   "metadata": {},
   "source": [
    "# Kruskal Dunn tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3d674",
   "metadata": {},
   "source": [
    "### Compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ed3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal results:\n",
      "F-statistic: 79.488\n",
      "p-value: 5.488e-18\n"
     ]
    }
   ],
   "source": [
    "label_com = values_by_label(Liar_computed, 'compressed_size',labels, df_label)\n",
    "stat, p = kruskal(*label_com) # unpack the elements \n",
    "\n",
    "print('Kruskal results:')\n",
    "print(f'F-statistic: {stat:.3f}')\n",
    "print(f'p-value: {p:.3e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55e15ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results for the information complexity\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.000049   True  0.028887   True\n",
      "2       0.000049   True       1.0  False       0.0   True\n",
      "3       0.028887   True       0.0   True       1.0  False\n"
     ]
    }
   ],
   "source": [
    "dunn_results = sp.posthoc_dunn(label_com, p_adjust='bonferroni')\n",
    "print('Dunn results for the information complexity')\n",
    "df_dunn_IC = dunn_table(dunn_results)\n",
    "print(df_dunn_IC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9451f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "    1 & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      " 1.00 &  False &  0.00 &   True &  0.03 &   True \\\\\n",
      " 0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      " 0.03 &   True &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3111311640.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_DIC = df_dunn_IC.to_latex(index=False, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "latex_table_DIC = df_dunn_IC.to_latex(index=False, float_format=lambda x: \"%.2f\" % x)\n",
    "print(latex_table_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09e6b8",
   "metadata": {},
   "source": [
    "### Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000583f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal results:\n",
      "F-statistic: 49.863\n",
      "p-value: 1.487e-11\n"
     ]
    }
   ],
   "source": [
    "label_fke = values_by_label(Liar_computed, 'readability',labels,df_label)\n",
    "stat, p = kruskal(*label_fke) # unpack the elements \n",
    "\n",
    "print('Kruskal results:')\n",
    "print(f'F-statistic: {stat:.3f}')\n",
    "print(f'p-value: {p:.3e}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd28acaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results for the FKE-readability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "      <th>value</th>\n",
       "      <th>reject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012227</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "group          1            2                3       \n",
       "metric     value reject value reject     value reject\n",
       "1            1.0  False   0.0   True  0.012227   True\n",
       "2            0.0   True   1.0  False       0.0   True\n",
       "3       0.012227   True   0.0   True       1.0  False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunn_results = sp.posthoc_dunn(label_fke, p_adjust='bonferroni')\n",
    "df_dunn_R = dunn_table(dunn_results)\n",
    "\n",
    "print('Dunn results for the FKE-readability')\n",
    "dunn_table(dunn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e2d2ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.01 &   True \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.01 &   True &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/2998737089.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df_dunn_R.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "latex_table = df_dunn_R.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891b7e8",
   "metadata": {},
   "source": [
    "### VADER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46e8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vader_neg : fstat 10.409693080422452; p 0.005489892854085175\n",
      "vader_neu : fstat 10.17546297354846; p 0.00617200529376983\n",
      "vader_pos : fstat 4.323321766239063; p 0.11513373846730762\n",
      "vader_compound : fstat 1.999867736891534; p 0.36790377041511385\n"
     ]
    }
   ],
   "source": [
    "vader_labels = ['vader_neg', 'vader_neu', 'vader_pos', 'vader_compound']\n",
    "\n",
    "computed_labels = []\n",
    "for vader in vader_labels:\n",
    "    label_vader = values_by_label(Liar_computed, vader,labels,df_label)\n",
    "    stat, p = kruskal(*label_vader) # unpack the elements\n",
    "    computed_labels.append([stat, p])\n",
    "\n",
    "for i, (stat, p), vader in zip(range(len(computed_labels)), computed_labels, vader_labels):\n",
    "    print(f'{vader} : fstat {stat}; p {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3966323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18d974b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results: vader_neg\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False       1.0  False  0.022119   True\n",
      "2            1.0  False       1.0  False  0.041474   True\n",
      "3       0.022119   True  0.041474   True       1.0  False\n",
      "Dunn results: vader_neu\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.060342  False  0.004317   True\n",
      "2       0.060342  False       1.0  False       1.0  False\n",
      "3       0.004317   True       1.0  False       1.0  False\n",
      "Dunn results: vader_pos\n",
      "group          1                2                3       \n",
      "metric     value reject     value reject     value reject\n",
      "1            1.0  False  0.144254  False  0.197013  False\n",
      "2       0.144254  False       1.0  False       1.0  False\n",
      "3       0.197013  False       1.0  False       1.0  False\n",
      "Dunn results: vader_compound\n",
      "group      1                2                3       \n",
      "metric value reject     value reject     value reject\n",
      "1        1.0  False       1.0  False       1.0  False\n",
      "2        1.0  False       1.0  False  0.516025  False\n",
      "3        1.0  False  0.516025  False       1.0  False\n"
     ]
    }
   ],
   "source": [
    "df_dict = {\n",
    "    \"vader_neg\": pd.DataFrame(),\n",
    "    \"vader_neu\": pd.DataFrame(),\n",
    "    \"vader_pos\": pd.DataFrame(),\n",
    "    \"vader_compound\": pd.DataFrame()\n",
    "}\n",
    "\n",
    "for vader in vader_labels:\n",
    "    label_vader = values_by_label(Liar_computed, vader, labels, df_label)\n",
    "    dunn_results = sp.posthoc_dunn(label_vader, p_adjust='bonferroni')\n",
    "    result_dunn_test = dunn_table(dunn_results)\n",
    "    \n",
    "    df_dict[vader] = result_dunn_test\n",
    "        \n",
    "    print(f'Dunn results: {vader}')\n",
    "    print(result_dunn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5ae5435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results index         1                2                3         \\\n",
      "metric                 value reject     value reject     value reject   \n",
      "0                1       1.0  False       1.0  False  0.022119   True   \n",
      "1                2       1.0  False       1.0  False  0.041474   True   \n",
      "2                3  0.022119   True  0.041474   True       1.0  False   \n",
      "\n",
      "Dunn results         1                2  ...                          3  \\\n",
      "metric           value reject     value  ...     value reject     value   \n",
      "0                  1.0  False  0.060342  ...  0.144254  False  0.197013   \n",
      "1             0.060342  False       1.0  ...       1.0  False       1.0   \n",
      "2             0.004317   True       1.0  ...       1.0  False       1.0   \n",
      "\n",
      "Dunn results            1                2                3         \n",
      "metric       reject value reject     value reject     value reject  \n",
      "0             False   1.0  False       1.0  False       1.0  False  \n",
      "1             False   1.0  False       1.0  False  0.516025  False  \n",
      "2             False   1.0  False  0.516025  False       1.0  False  \n",
      "\n",
      "[3 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/4196658005.py:5: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  vader_results = vader_results.reset_index()\n"
     ]
    }
   ],
   "source": [
    "vader_results = pd.concat([df_dict[\"vader_neg\"], df_dict[\"vader_neu\"], df_dict[\"vader_pos\"], df_dict[\"vader_compound\"]], axis=1)\n",
    "\n",
    "vader_results.columns = vader_results.columns.set_names(['Dunn results', 'metric'])\n",
    "\n",
    "vader_results = vader_results.reset_index()\n",
    "\n",
    "print(vader_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84db760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/465134394.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_vader = vader_results.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "latex_table_vader = vader_results.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fa5f7",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08bc2383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER count results:\n",
      "F-statistic: 42.182\n",
      "p-value: 6.924e-10\n",
      "Dunn results for the FKE-readability\n"
     ]
    }
   ],
   "source": [
    "label_ner_sum = values_by_label(Liar_computed, 'tot_ner_count',labels,df_label)\n",
    "stat, p = kruskal(*label_ner_sum) \n",
    "\n",
    "print('NER count results:')\n",
    "print(f'F-statistic: {stat:.3f}')\n",
    "print(f'p-value: {p:.3e}')\n",
    "\n",
    "dunn_results = sp.posthoc_dunn(label_ner_sum, p_adjust='bonferroni')\n",
    "\n",
    "\n",
    "print('Dunn results for the FKE-readability')\n",
    "df_dunn_NER = dunn_table(dunn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b1eea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.41 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.41 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/4272445514.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df_dunn_NER.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "latex_table = df_dunn_NER.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d07872",
   "metadata": {},
   "source": [
    "### NER counts tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75dac54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER_CARDINAL : fstat 49.83110092286668; p 1.5111720797740373e-11\n",
      "NER_DATE : fstat 51.61532051517984; p 6.192636087610597e-12\n",
      "NER_EVENT : fstat 0.17192881583577338; p 0.9176268908905847\n",
      "NER_FAC : fstat 1.62191142550578; p 0.44443311279487685\n",
      "NER_GPE : fstat 4.891785484232781; p 0.08664874537809603\n",
      "NER_LANGUAGE : fstat 0.2765099377408568; p 0.8708766170086077\n",
      "NER_LAW : fstat 5.044810889786552; p 0.08026629818911608\n",
      "NER_LOC : fstat 0.4509002696889834; p 0.7981568596715132\n",
      "NER_MONEY : fstat 35.30762339462919; p 2.1530147012843794e-08\n",
      "NER_NORP : fstat 0.7534040417699982; p 0.6861204930154862\n",
      "NER_ORDINAL : fstat 13.269417872165102; p 0.0013139611361827818\n",
      "NER_ORG : fstat 15.497830751288278; p 0.00043120998788284286\n",
      "NER_PERCENT : fstat 51.19931270863278; p 7.624484865681605e-12\n",
      "NER_PERSON : fstat 82.52962410037611; p 1.1992778976434277e-18\n",
      "NER_PRODUCT : fstat 1.096845519071406; p 0.5778605169801413\n",
      "NER_QUANTITY : fstat 3.320164395658514; p 0.19012335173241685\n",
      "NER_TIME : fstat 3.710352636538486; p 0.15642535959465625\n",
      "NER_WORK_OF_ART : fstat 9.313248559339161; p 0.00949847252951896\n"
     ]
    }
   ],
   "source": [
    "ner_labels = [ 'NER_CARDINAL',\n",
    "       'NER_DATE', 'NER_EVENT', 'NER_FAC', 'NER_GPE', 'NER_LANGUAGE',\n",
    "       'NER_LAW', 'NER_LOC', 'NER_MONEY', 'NER_NORP', 'NER_ORDINAL', 'NER_ORG',\n",
    "       'NER_PERCENT', 'NER_PERSON', 'NER_PRODUCT', 'NER_QUANTITY', 'NER_TIME',\n",
    "       'NER_WORK_OF_ART']\n",
    "computed_ner_labels = []\n",
    "for ner in ner_labels:\n",
    "    label_ner = values_by_label(Liar_computed, ner, labels, df_label)\n",
    "    stat, p = kruskal(*label_ner) # unpack the elements \n",
    "    computed_ner_labels.append([stat, p])\n",
    "\n",
    "for i, (stat, p), pos in zip(range(len(computed_ner_labels)), computed_ner_labels, ner_labels):\n",
    "       print(f'{pos} : fstat {stat}; p {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dfe189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_ner = {}\n",
    "for label in ner_labels:\n",
    "    df_dict_ner[label] = pd.DataFrame()\n",
    "\n",
    "\n",
    "for ner in ner_labels:\n",
    "    label_ner = values_by_label(Liar_computed, ner, labels, df_label)\n",
    "    dunn_results = sp.posthoc_dunn(label_ner, p_adjust='bonferroni')\n",
    "    result_dunn_test_ner = dunn_table(dunn_results)\n",
    "    \n",
    "    df_dict_ner[ner] = result_dunn_test_ner\n",
    "        \n",
    "    #print(f'Dunn results: {ner}')\n",
    "    #print(result_dunn_test_ner)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12ec3e56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results index         1                2                3       \n",
      "metric                 value reject     value reject     value reject\n",
      "0                1       1.0  False       0.0   True       1.0  False\n",
      "1                2       0.0   True       1.0  False       0.0   True\n",
      "2                3       1.0  False       0.0   True       1.0  False\n",
      "3                1       1.0  False       0.0   True  0.020809   True\n",
      "4                2       0.0   True       1.0  False       0.0   True\n",
      "5                3  0.020809   True       0.0   True       1.0  False\n",
      "6                1       1.0  False       1.0  False       1.0  False\n",
      "7                2       1.0  False       1.0  False       1.0  False\n",
      "8                3       1.0  False       1.0  False       1.0  False\n",
      "9                1       1.0  False  0.644083  False  0.852657  False\n",
      "10               2  0.644083  False       1.0  False       1.0  False\n",
      "11               3  0.852657  False       1.0  False       1.0  False\n",
      "12               1       1.0  False  0.088336  False  0.644748  False\n",
      "13               2  0.088336  False       1.0  False  0.464986  False\n",
      "14               3  0.644748  False  0.464986  False       1.0  False\n",
      "15               1       1.0  False       1.0  False       1.0  False\n",
      "16               2       1.0  False       1.0  False       1.0  False\n",
      "17               3       1.0  False       1.0  False       1.0  False\n",
      "18               1       1.0  False  0.253646  False  0.076469  False\n",
      "19               2  0.253646  False       1.0  False       1.0  False\n",
      "20               3  0.076469  False       1.0  False       1.0  False\n",
      "21               1       1.0  False       1.0  False       1.0  False\n",
      "22               2       1.0  False       1.0  False       1.0  False\n",
      "23               3       1.0  False       1.0  False       1.0  False\n",
      "24               1       1.0  False       1.0  False  0.000786   True\n",
      "25               2       1.0  False       1.0  False       0.0   True\n",
      "26               3  0.000786   True       0.0   True       1.0  False\n",
      "27               1       1.0  False       1.0  False       1.0  False\n",
      "28               2       1.0  False       1.0  False       1.0  False\n",
      "29               3       1.0  False       1.0  False       1.0  False\n",
      "30               1       1.0  False  0.000855   True  0.064517  False\n",
      "31               2  0.000855   True       1.0  False    0.1102  False\n",
      "32               3  0.064517  False    0.1102  False       1.0  False\n",
      "33               1       1.0  False  0.003574   True       1.0  False\n",
      "34               2  0.003574   True       1.0  False  0.001141   True\n",
      "35               3       1.0  False  0.001141   True       1.0  False\n",
      "36               1       1.0  False       0.0   True  0.674264  False\n",
      "37               2       0.0   True       1.0  False       0.0   True\n",
      "38               3  0.674264  False       0.0   True       1.0  False\n",
      "39               1       1.0  False       0.0   True       0.0   True\n",
      "40               2       0.0   True       1.0  False  0.000813   True\n",
      "41               3       0.0   True  0.000813   True       1.0  False\n",
      "42               1       1.0  False       1.0  False  0.900096  False\n",
      "43               2       1.0  False       1.0  False       1.0  False\n",
      "44               3  0.900096  False       1.0  False       1.0  False\n",
      "45               1       1.0  False  0.218648  False  0.923014  False\n",
      "46               2  0.218648  False       1.0  False  0.722318  False\n",
      "47               3  0.923014  False  0.722318  False       1.0  False\n",
      "48               1       1.0  False  0.457972  False       1.0  False\n",
      "49               2  0.457972  False       1.0  False  0.201008  False\n",
      "50               3       1.0  False  0.201008  False       1.0  False\n",
      "51               1       1.0  False  0.586245  False  0.842654  False\n",
      "52               2  0.586245  False       1.0  False  0.007074   True\n",
      "53               3  0.842654  False  0.007074   True       1.0  False\n"
     ]
    }
   ],
   "source": [
    "df_list_ner = []\n",
    "\n",
    "for label in df_dict_ner.keys():\n",
    "    df_list_ner.append(df_dict_ner[label])\n",
    "\n",
    "result_ner_tag = pd.concat(df_list_ner, axis=0)\n",
    "\n",
    "result_ner_tag.columns = result_ner_tag.columns.set_names(['Dunn results', 'metric'])\n",
    "result_ner_tag = result_ner_tag.reset_index()\n",
    "\n",
    "print(result_ner_tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f114025",
   "metadata": {},
   "source": [
    "### Significant features:\n",
    "- CARDINAL p 0.0\n",
    "- DATE  p 0.0\n",
    "- ORDINAL p 0.0\n",
    "- ORG p 0.0\n",
    "- PERCENT 0.0\n",
    "- PERSON 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a1f5dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3463907403.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_ner_tags = result_ner_tag.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "latex_table_ner_tags = result_ner_tag.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "#print(latex_table_ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e8858",
   "metadata": {},
   "source": [
    "### Pos labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b079fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_ADJ : fstat 75.63363133229193; p 3.7702107990073795e-17\n",
      "pos_ADP : fstat 52.88463642780589; p 3.2828203050086716e-12\n",
      "pos_ADV : fstat 15.343928130378757; p 0.000465702255291164\n",
      "pos_AUX : fstat 10.672755272313356; p 0.004813274601537372\n",
      "pos_CCONJ : fstat 30.78256967100686; p 2.0684733341776858e-07\n",
      "pos_DET : fstat 17.70000951293461; p 0.0001433810542873743\n",
      "pos_INTJ : fstat 1.6205299951697043; p 0.44474019552820465\n",
      "pos_NOUN : fstat 74.42562883952174; p 6.897314694451533e-17\n",
      "pos_NUM : fstat 157.83110536457033; p 5.33839781071815e-35\n",
      "pos_PART : fstat 15.798490526270482; p 0.0003710234598959158\n",
      "pos_PRON : fstat 6.770194727289172; p 0.03387434405551494\n",
      "pos_PROPN : fstat 49.15895156684152; p 2.1147999875958165e-11\n",
      "pos_PUNCT : fstat 39.48929409787203; p 2.6607786034061635e-09\n",
      "pos_SCONJ : fstat 50.565192976835576; p 1.0469064051354758e-11\n",
      "pos_SYM : fstat 27.912685893597782; p 8.686348924034588e-07\n",
      "pos_VERB : fstat 45.05819719363287; p 1.6433754586485928e-10\n",
      "pos_X : fstat 4.769992151936845; p 0.092089340940054\n"
     ]
    }
   ],
   "source": [
    "pos_labels = [ 'pos_ADJ',\n",
    "       'pos_ADP', 'pos_ADV', 'pos_AUX', 'pos_CCONJ', 'pos_DET', 'pos_INTJ',\n",
    "       'pos_NOUN', 'pos_NUM', 'pos_PART', 'pos_PRON', 'pos_PROPN', 'pos_PUNCT',\n",
    "       'pos_SCONJ', 'pos_SYM', 'pos_VERB', 'pos_X']\n",
    "\n",
    "computed_pos_labels = []\n",
    "for pos in pos_labels:\n",
    "    label_pos = values_by_label(Liar_computed, pos, labels, df_label)\n",
    "    stat, p = kruskal(*label_pos) # unpack the elements\n",
    "    computed_pos_labels.append([stat, p])\n",
    "\n",
    "for i, (stat, p), pos in zip(range(len(computed_pos_labels)), computed_pos_labels, pos_labels):\n",
    "       print(f'{pos} : fstat {stat}; p {p}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7bcddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results: pos_ADJ\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.90 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.90 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_ADP\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  1.00 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn results: pos_ADV\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  1.00 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_AUX\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.01 &   True &  0.01 &   True \\\\\n",
      "2 &  0.01 &   True &  1.00 &  False &  1.00 &  False \\\\\n",
      "3 &  0.01 &   True &  1.00 &  False &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_CCONJ\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.05 &   True &  0.17 &  False \\\\\n",
      "2 &  0.05 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.17 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_DET\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  1.00 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_INTJ\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  1.00 &  False &  1.00 &  False \\\\\n",
      "2 &  1.00 &  False &  1.00 &  False &  0.61 &  False \\\\\n",
      "3 &  1.00 &  False &  0.61 &  False &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_NOUN\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.68 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.68 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_NUM\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  1.00 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_PART\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.02 &   True \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.12 &  False \\\\\n",
      "3 &  0.02 &   True &  0.12 &  False &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_PRON\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.09 &  False &  1.00 &  False \\\\\n",
      "2 &  0.09 &  False &  1.00 &  False &  0.06 &  False \\\\\n",
      "3 &  1.00 &  False &  0.06 &  False &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_PROPN\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.00 &   True \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.00 &   True &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_PUNCT\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.68 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.68 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_SCONJ\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.18 &  False \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.18 &  False &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_SYM\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  1.00 &  False &  0.00 &   True \\\\\n",
      "2 &  1.00 &  False &  1.00 &  False &  0.00 &   True \\\\\n",
      "3 &  0.00 &   True &  0.00 &   True &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_VERB\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.00 &   True &  0.00 &   True \\\\\n",
      "2 &  0.00 &   True &  1.00 &  False &  0.11 &  False \\\\\n",
      "3 &  0.00 &   True &  0.11 &  False &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Dunn results: pos_X\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "group & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{3} \\\\\n",
      "metric & value & reject & value & reject & value & reject \\\\\n",
      "\\midrule\n",
      "1 &  1.00 &  False &  0.09 &  False &  0.26 &  False \\\\\n",
      "2 &  0.09 &  False &  1.00 &  False &  1.00 &  False \\\\\n",
      "3 &  0.26 &  False &  1.00 &  False &  1.00 &  False \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/3555256661.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "for pos in pos_labels:\n",
    "    label_pos = values_by_label(Liar_computed, pos,labels,df_label)\n",
    "    dunn_results = sp.posthoc_dunn(label_pos, p_adjust='bonferroni')\n",
    "    a = dunn_table(dunn_results)\n",
    "    latex_table_pos = a.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "    print(f'Dunn results: {pos}')\n",
    "    print(latex_table_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adfada9",
   "metadata": {},
   "source": [
    "### Significant POS features\n",
    "- ADJ p: 0.00\n",
    "- ADP p: 0.00\n",
    "- AUX p: 0.01\n",
    "- CCONJ p: 0.05\n",
    "- DET p: 0.00\n",
    "- NOUN p: 0.00\n",
    "- NUM p:0.00\n",
    "- PART p:0.00\n",
    "- PUNCT p:0.00\n",
    "- SCONJ p: 0.00\n",
    "- VERB p:0 .00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af59d7f",
   "metadata": {},
   "source": [
    "## aggregate results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cd92cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(df, column_name):\n",
    "    avg = df[column_name].mean()\n",
    "    max_val = df[column_name].max()\n",
    "    mode = df[column_name].mode()[0]\n",
    "    std = df[column_name].std()\n",
    "    return pd.DataFrame({'avg': [avg], 'max': [max_val], 'most common': [mode], 'std': [std]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9412f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = ['compressed_size', 'readability']\n",
    "df_Liar_true_agg = df_Liar_true[stat_columns]\n",
    "df_Liar_false_agg = df_Liar_false[stat_columns]\n",
    "df_Liar_between_agg = df_Liar_between[stat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d55d8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = ['compressed_size', 'readability']\n",
    "labels = [0, 1, 2]\n",
    "\n",
    "rows = []\n",
    "for feature in stat_columns:\n",
    "    for label in labels:\n",
    "        df = Liar_computed[Liar_computed['binary label'] == label][[feature]]\n",
    "        stats = get_stats(df, feature)\n",
    "        rows.append({'feature': feature, 'label': label, 'avg': stats.iloc[0]['avg'], 'max': stats.iloc[0]['max'], \n",
    "                     'most common': stats.iloc[0]['most common'],'std': stats.iloc[0]['std']})\n",
    "        \n",
    "df_stats = pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b2c1178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  label          avg            max  most common  \\\n",
      "0  compressed_size      0  8555.133055  149837.000000  5592.000000   \n",
      "1  compressed_size      1  8130.459583  197589.000000  5964.000000   \n",
      "2  compressed_size      2  8775.910471  294076.000000  5951.000000   \n",
      "3      readability      0    60.759599     127.215714    74.270000   \n",
      "4      readability      1    56.334270     124.155000    60.705000   \n",
      "5      readability      2    59.047204     151.000000    56.978462   \n",
      "\n",
      "           std  \n",
      "0  4779.259754  \n",
      "1  4929.506473  \n",
      "2  5112.168963  \n",
      "3    21.520138  \n",
      "4    22.948483  \n",
      "5    22.439190  \n"
     ]
    }
   ],
   "source": [
    "print(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b4d40d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "        feature &  label &     avg &       max &  most common &     std \\\\\n",
      "\\midrule\n",
      "compressed\\_size &      0 & 8555.13 & 149837.00 &      5592.00 & 4779.26 \\\\\n",
      "compressed\\_size &      1 & 8130.46 & 197589.00 &      5964.00 & 4929.51 \\\\\n",
      "compressed\\_size &      2 & 8775.91 & 294076.00 &      5951.00 & 5112.17 \\\\\n",
      "    readability &      0 &   60.76 &    127.22 &        74.27 &   21.52 \\\\\n",
      "    readability &      1 &   56.33 &    124.16 &        60.71 &   22.95 \\\\\n",
      "    readability &      2 &   59.05 &    151.00 &        56.98 &   22.44 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/2196185760.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df_stats.to_latex(index=False, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a dataframe called stats_df\n",
    "latex_table = df_stats.to_latex(index=False, float_format=lambda x: \"%.2f\" % x)\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456787c3",
   "metadata": {},
   "source": [
    "### Discrete values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96eef43",
   "metadata": {},
   "source": [
    "- total sum of the counts\n",
    "- average sum of count /total\n",
    "- max number of count for a individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0314bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_features = ['tot_ner_count','NER_CARDINAL', 'NER_DATE','NER_ORDINAL', 'NER_ORG','NER_PERCENT', 'NER_PERSON', \n",
    "                  'pos_ADJ','pos_ADP','pos_AUX', 'pos_CCONJ', 'pos_DET', 'pos_NOUN','pos_NUM','pos_PART',\n",
    "                    'pos_PUNCT', 'pos_SCONJ','pos_VERB', ]\n",
    "df_Liar_true_count = df_Liar_true[count_features]\n",
    "df_Liar_false_count = df_Liar_false[count_features]\n",
    "df_Liar_between_count = df_Liar_between[count_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6b96ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Max Counts                 avg                 std\n",
      "Feature                                                             \n",
      "tot_ner_count   (42, 59, 69)  (2.28, 2.12, 2.33)  (1.76, 1.78, 1.74)\n",
      "NER_CARDINAL       (5, 5, 6)  (0.29, 0.19, 0.28)   (0.6, 0.48, 0.58)\n",
      "NER_DATE           (5, 4, 4)  (0.32, 0.21, 0.28)  (0.62, 0.48, 0.57)\n",
      "NER_ORDINAL        (2, 2, 3)  (0.05, 0.03, 0.04)  (0.24, 0.18, 0.21)\n",
      "NER_ORG          (7, 12, 16)  (0.32, 0.36, 0.32)  (0.63, 0.64, 0.63)\n",
      "NER_PERCENT        (4, 3, 6)  (0.16, 0.08, 0.14)   (0.47, 0.3, 0.41)\n",
      "NER_PERSON       (11, 9, 11)  (0.34, 0.51, 0.45)  (0.66, 0.71, 0.68)\n",
      "pos_ADJ         (21, 32, 45)  (1.34, 1.07, 1.31)   (1.34, 1.23, 1.4)\n",
      "pos_ADP         (20, 27, 31)  (2.19, 1.95, 2.18)  (1.55, 1.54, 1.59)\n",
      "pos_AUX           (8, 8, 11)   (1.0, 0.92, 0.92)  (0.99, 0.96, 0.95)\n",
      "pos_CCONJ          (5, 4, 7)   (0.35, 0.3, 0.38)  (0.62, 0.58, 0.64)\n",
      "pos_DET         (23, 33, 39)   (2.01, 1.85, 2.0)  (1.59, 1.57, 1.64)\n",
      "pos_NOUN       (59, 76, 129)  (4.22, 3.87, 4.33)   (2.64, 2.7, 2.93)\n",
      "pos_NUM         (31, 56, 70)   (0.89, 0.62, 0.9)  (1.36, 1.44, 1.47)\n",
      "pos_PART          (4, 6, 10)  (0.39, 0.46, 0.43)   (0.69, 0.7, 0.71)\n",
      "pos_PUNCT      (55, 65, 106)  (2.16, 2.03, 2.21)  (1.94, 1.89, 2.06)\n",
      "pos_SCONJ          (4, 8, 8)  (0.44, 0.34, 0.42)  (0.65, 0.63, 0.67)\n",
      "pos_VERB        (18, 18, 37)   (2.12, 2.32, 2.4)  (1.61, 1.64, 1.69)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_counts = pd.concat([df_Liar_true[count_features].max(axis=0), df_Liar_false[count_features].max(axis=0),\n",
    "                        df_Liar_between[count_features].max(axis=0)], axis=1)\n",
    "avg = pd.concat([df_Liar_true[count_features].mean(axis=0), df_Liar_false[count_features].mean(axis=0),\n",
    "                        df_Liar_between[count_features].mean(axis=0)], axis=1)\n",
    "\n",
    "std = pd.concat([df_Liar_true[count_features].std(axis=0), df_Liar_false[count_features].std(axis=0),\n",
    "                 df_Liar_between[count_features].std(axis=0)], axis=1)\n",
    "feature_count_stats = pd.DataFrame(index=count_features, columns=['Max Counts','avg','std'])\n",
    "\n",
    "\n",
    "feature_count_stats['std'] = list(zip(std[0].round(2), std[1].round(2), std[2].round(2)))\n",
    "\n",
    "\n",
    "feature_count_stats['Max Counts'] = list(zip(max_counts[0].astype(int), max_counts[1].astype(int), max_counts[2].astype(int)))\n",
    "feature_count_stats['avg'] = list(zip(avg[0].round(2), avg[1].round(2), avg[2].round(2)))\n",
    "\n",
    "\n",
    "feature_count_stats.index.name = 'Feature'\n",
    "\n",
    "print(feature_count_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98fb9c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &     Max Counts &                 avg &                 std \\\\\n",
      "Feature       &                &                     &                     \\\\\n",
      "\\midrule\n",
      "tot\\_ner\\_count &   (42, 59, 69) &  (2.28, 2.12, 2.33) &  (1.76, 1.78, 1.74) \\\\\n",
      "NER\\_CARDINAL  &      (5, 5, 6) &  (0.29, 0.19, 0.28) &   (0.6, 0.48, 0.58) \\\\\n",
      "NER\\_DATE      &      (5, 4, 4) &  (0.32, 0.21, 0.28) &  (0.62, 0.48, 0.57) \\\\\n",
      "NER\\_ORDINAL   &      (2, 2, 3) &  (0.05, 0.03, 0.04) &  (0.24, 0.18, 0.21) \\\\\n",
      "NER\\_ORG       &    (7, 12, 16) &  (0.32, 0.36, 0.32) &  (0.63, 0.64, 0.63) \\\\\n",
      "NER\\_PERCENT   &      (4, 3, 6) &  (0.16, 0.08, 0.14) &   (0.47, 0.3, 0.41) \\\\\n",
      "NER\\_PERSON    &    (11, 9, 11) &  (0.34, 0.51, 0.45) &  (0.66, 0.71, 0.68) \\\\\n",
      "pos\\_ADJ       &   (21, 32, 45) &  (1.34, 1.07, 1.31) &   (1.34, 1.23, 1.4) \\\\\n",
      "pos\\_ADP       &   (20, 27, 31) &  (2.19, 1.95, 2.18) &  (1.55, 1.54, 1.59) \\\\\n",
      "pos\\_AUX       &     (8, 8, 11) &   (1.0, 0.92, 0.92) &  (0.99, 0.96, 0.95) \\\\\n",
      "pos\\_CCONJ     &      (5, 4, 7) &   (0.35, 0.3, 0.38) &  (0.62, 0.58, 0.64) \\\\\n",
      "pos\\_DET       &   (23, 33, 39) &   (2.01, 1.85, 2.0) &  (1.59, 1.57, 1.64) \\\\\n",
      "pos\\_NOUN      &  (59, 76, 129) &  (4.22, 3.87, 4.33) &   (2.64, 2.7, 2.93) \\\\\n",
      "pos\\_NUM       &   (31, 56, 70) &   (0.89, 0.62, 0.9) &  (1.36, 1.44, 1.47) \\\\\n",
      "pos\\_PART      &     (4, 6, 10) &  (0.39, 0.46, 0.43) &   (0.69, 0.7, 0.71) \\\\\n",
      "pos\\_PUNCT     &  (55, 65, 106) &  (2.16, 2.03, 2.21) &  (1.94, 1.89, 2.06) \\\\\n",
      "pos\\_SCONJ     &      (4, 8, 8) &  (0.44, 0.34, 0.42) &  (0.65, 0.63, 0.67) \\\\\n",
      "pos\\_VERB      &   (18, 18, 37) &   (2.12, 2.32, 2.4) &  (1.61, 1.64, 1.69) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/8tgppr255xx8v40x26xhhmhr0000gn/T/ipykernel_4240/2675997809.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = feature_count_stats.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n"
     ]
    }
   ],
   "source": [
    "latex_table = feature_count_stats.to_latex(index=True, float_format=lambda x: \"%.2f\" % x)\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
